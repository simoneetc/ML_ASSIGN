{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb97baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b7484",
   "metadata": {},
   "source": [
    "imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5f1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix,\\\n",
    "ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split,\\\n",
    "cross_validate, cross_val_score, ShuffleSplit, \\\n",
    "RandomizedSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548ba1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(306) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a8d8a",
   "metadata": {},
   "source": [
    "shuffle-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2311bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4335e9",
   "metadata": {},
   "source": [
    "download and spliting into test/taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281150cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "features, labels = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "labels *=100\n",
    "\n",
    "# train-test split\n",
    "com_train_features, test_features, com_train_labels, test_labels = \\\n",
    "    train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# train --> train + dev split\n",
    "train_features, dev_features, train_labels, dev_labels = \\\n",
    "    train_test_split(com_train_features, com_train_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec3cb48",
   "metadata": {},
   "source": [
    "Training diff. regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e01cdff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regressor(estimator, X_train, y_train, cv, name):\n",
    "    cv_results = cross_validate(estimator,\n",
    "                               X_train,\n",
    "                               y_train,\n",
    "                               cv=cv,\n",
    "                               scoring=\"neg_mean_absolute_error\",\n",
    "                               return_train_score=True,\n",
    "                               return_estimator=True)\n",
    "    \n",
    "    cv_train_error = -1 * cv_results['train_score']\n",
    "    cv_test_error = -1 * cv_results['test_score']\n",
    "    \n",
    "    print(f\"On an average, {name} makes an error of \"\n",
    "          f\"{cv_train_error.mean():.3f}k +/- {cv_train_error.std():.3f}k on the training set.\")\n",
    "    print(f\"On an average, {name} makes an error of \"\n",
    "          f\"{cv_test_error.mean():.3f}k +/- {cv_test_error.std():.3f}k on the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab891238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On an average, random forest regressor makes an error of 12.643k +/- 0.061k on the training set.\n",
      "On an average, random forest regressor makes an error of 33.129k +/- 0.701k on the test set.\n"
     ]
    }
   ],
   "source": [
    "train_regressor(\n",
    "    RandomForestRegressor(), com_train_features,\\\n",
    "    com_train_labels, cv, 'random forest regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c1384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyperparameter tuning using GridSearchCV with a RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d0b149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'max_leaf_nodes': 100, 'n_estimators': 200}\n",
      "\n",
      "Best Mean Test Error: 40.5687594290511\n",
      "\n",
      "Results Table:\n",
      "   param_n_estimators param_max_leaf_nodes  mean_test_error  std_test_error\n",
      "52                200                  100        40.568759        0.708010\n",
      "53                500                  100        40.611287        0.782177\n",
      "51                100                  100        40.631864        0.703829\n",
      "50                 50                  100        40.910324        0.688116\n",
      "49                 20                  100        41.001398        0.737265\n",
      "48                 10                  100        41.472686        0.512427\n",
      "47                  5                  100        41.980259        1.023331\n",
      "41                 50                   50        43.798228        0.904086\n",
      "43                200                   50        43.803850        0.769831\n",
      "44                500                   50        43.839888        0.773010\n",
      "42                100                   50        43.852355        0.810270\n",
      "46                  2                  100        43.869636        0.837259\n",
      "40                 20                   50        44.029096        0.959440\n",
      "39                 10                   50        44.292641        1.080595\n",
      "38                  5                   50        44.766607        0.925887\n",
      "45                  1                  100        45.892705        1.839387\n",
      "37                  2                   50        46.080858        0.985569\n",
      "35                500                   20        49.474766        1.107309\n",
      "32                 50                   20        49.502562        1.032599\n",
      "34                200                   20        49.521271        1.083976\n",
      "33                100                   20        49.585423        1.033816\n",
      "31                 20                   20        49.696894        1.259800\n",
      "30                 10                   20        49.920011        1.103347\n",
      "36                  1                   50        49.970896        1.381239\n",
      "29                  5                   20        50.238146        1.420624\n",
      "28                  2                   20        51.515778        0.450578\n",
      "27                  1                   20        53.158869        0.858160\n",
      "24                100                   10        54.989416        1.004576\n",
      "26                500                   10        55.012612        1.061848\n",
      "23                 50                   10        55.033963        1.102023\n",
      "25                200                   10        55.045782        1.098695\n",
      "22                 20                   10        55.195141        1.001881\n",
      "21                 10                   10        55.364999        1.204779\n",
      "20                  5                   10        55.962478        1.035932\n",
      "19                  2                   10        56.294967        0.608862\n",
      "18                  1                   10        58.213599        1.094278\n",
      "15                100                    5        61.195574        1.003693\n",
      "17                500                    5        61.220994        1.041844\n",
      "16                200                    5        61.278414        1.077164\n",
      "14                 50                    5        61.318100        1.039589\n",
      "12                 10                    5        61.331098        1.141548\n",
      "13                 20                    5        61.369516        1.156799\n",
      "11                  5                    5        61.631519        1.045174\n",
      "10                  2                    5        62.114703        0.890272\n",
      "9                   1                    5        63.024072        0.907155\n",
      "2                   5                    2        72.850689        0.924892\n",
      "8                 500                    2        72.987933        1.037957\n",
      "4                  20                    2        73.001786        1.038621\n",
      "6                 100                    2        73.009828        1.135507\n",
      "7                 200                    2        73.045525        1.084898\n",
      "5                  50                    2        73.065709        1.030114\n",
      "3                  10                    2        73.091541        1.025932\n",
      "1                   2                    2        73.715827        1.129815\n",
      "0                   1                    2        74.382305        0.602108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [1, 2, 5, 10, 20, 50, 100, 200, 500],\n",
    "    \"max_leaf_nodes\": [2, 5, 10, 20, 50, 100],\n",
    "}\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_cv = GridSearchCV(\n",
    "    RandomForestRegressor(n_jobs=2),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_cv.fit(com_train_features, com_train_labels)\n",
    "\n",
    "# Extract and display the results\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(grid_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "result_table = cv_results[columns].sort_values(by=\"mean_test_error\")\n",
    "\n",
    "# Display the best parameters and corresponding mean test error\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_cv.best_params_)\n",
    "print(\"\\nBest Mean Test Error:\", -grid_cv.best_score_)\n",
    "print(\"\\nResults Table:\")\n",
    "print(result_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e1b1e",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning using RandomizedSearchCV with a RandomForestRegressor (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56133a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>40.621985</td>\n",
       "      <td>0.769115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>41.302509</td>\n",
       "      <td>0.863997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>43.714186</td>\n",
       "      <td>0.799775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>46.436338</td>\n",
       "      <td>1.028120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>49.389446</td>\n",
       "      <td>1.150302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>49.467752</td>\n",
       "      <td>0.997048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>50.073348</td>\n",
       "      <td>1.218088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>54.983731</td>\n",
       "      <td>1.053561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>61.278826</td>\n",
       "      <td>0.942016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>73.487031</td>\n",
       "      <td>0.985396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_leaf_nodes  mean_test_error  std_test_error\n",
       "0                500                  100        40.621985        0.769115\n",
       "2                 10                  100        41.302509        0.863997\n",
       "7                100                   50        43.714186        0.799775\n",
       "8                  1                  100        46.436338        1.028120\n",
       "6                 50                   20        49.389446        1.150302\n",
       "1                100                   20        49.467752        0.997048\n",
       "9                 10                   20        50.073348        1.218088\n",
       "3                500                   10        54.983731        1.053561\n",
       "4                  5                    5        61.278826        0.942016\n",
       "5                  5                    2        73.487031        0.985396"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    \"n_estimators\": [1, 2, 5, 10, 20, 50, 100, 200, 500],\n",
    "    \"max_leaf_nodes\": [2, 5, 10, 20, 50, 100],\n",
    "}\n",
    "\n",
    "search_cv = RandomizedSearchCV(\n",
    "    RandomForestRegressor(n_jobs=2), param_distributions=param_distributions,\n",
    "    scoring=\"neg_mean_absolute_error\", n_iter=10, random_state=0, n_jobs=2,)\n",
    "\n",
    "search_cv.fit(com_train_features, com_train_labels)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_distributions.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(search_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"mean_test_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfb3da18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, our random forest regressor makes an error of 40.53 k$\n"
     ]
    }
   ],
   "source": [
    "error = -search_cv.score(test_features, test_labels)\n",
    "print(f\"On average, our random forest regressor makes an error of {error:.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a6af8",
   "metadata": {},
   "source": [
    " 2.creating a single pipeline that does the full data preparation plus the final prediction.\n",
    " Data preparation : feature selection, scaling, and a RandomForestRegressor\n",
    " Final prediction:fitted+prediction(showing results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c26aa0",
   "metadata": {},
   "source": [
    "3.transformer : SelectFromModel  used to select the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ec4d45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'regressor__n_estimators': 500, 'regressor__max_leaf_nodes': 50}\n",
      "\n",
      "Best Mean Test Error: 54.082240941424416\n",
      "\n",
      "Results Table:\n",
      "  param_regressor__n_estimators param_regressor__max_leaf_nodes  \\\n",
      "5                           500                              50   \n",
      "6                            20                              50   \n",
      "8                           500                              20   \n",
      "0                             2                              50   \n",
      "7                             2                              10   \n",
      "2                             1                              10   \n",
      "3                            50                               5   \n",
      "1                           100                               5   \n",
      "4                            20                               5   \n",
      "9                             2                               2   \n",
      "\n",
      "   mean_test_error  std_test_error  \n",
      "5        54.082241        1.132283  \n",
      "6        54.205617        1.092575  \n",
      "8        54.682871        1.108092  \n",
      "0        54.991947        1.044255  \n",
      "7        57.932225        0.829623  \n",
      "2        59.062376        1.101063  \n",
      "3        61.241632        1.024724  \n",
      "1        61.243033        1.081725  \n",
      "4        61.243507        1.201853  \n",
      "9        74.072901        0.684151  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hyperparameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    \"regressor__n_estimators\": [1, 2, 5, 10, 20, 50, 100, 200, 500],\n",
    "    \"regressor__max_leaf_nodes\": [2, 5, 10, 20, 50, 100],\n",
    "}\n",
    "\n",
    "# Instantiate the RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_jobs=2)\n",
    "\n",
    "# Create a pipeline with feature selection and regression\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(rf_reg)),\n",
    "    ('scaler', StandardScaler()),  # You can add other preprocessing steps here\n",
    "    ('regressor', rf_reg)\n",
    "])\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_iter=10,  # Number of parameter settings sampled\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "randomized_cv.fit(com_train_features, com_train_labels)\n",
    "\n",
    "# Extract and display the results\n",
    "columns = [f\"param_{name}\" for name in param_dist.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(randomized_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "result_table = cv_results[columns].sort_values(by=\"mean_test_error\")\n",
    "\n",
    "# Display the best parameters and corresponding mean test error\n",
    "print(\"Best Parameters:\")\n",
    "print(randomized_cv.best_params_)\n",
    "print(\"\\nBest Mean Test Error:\", -randomized_cv.best_score_)\n",
    "print(\"\\nResults Table:\")\n",
    "print(result_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
